{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below step is only for portfolio project. In real prod, need to use service principal to link storage account to Databricks\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\n",
    "    \"fs.azure.account.key.stenergyplatformadls.dfs.core.windows.net\",\n",
    "    \"ACCESS_KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating access to storage account from Databricks\n",
    "dbutils.fs.ls(\"abfss://bronze@stenergyplatformadls.dfs.core.windows.net/energy_trends/prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, coalesce, last, monotonically_increasing_id, lit, to_date, year, month, regexp_extract, expr, round\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import FloatType, DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fill_tablename(df_bronze):\n",
    "    # Adding a column to hold table name\n",
    "    df_with_table = df_bronze.withColumn(\n",
    "        \"table_name\",\n",
    "        when(col(\"generator_type\").rlike(\"(?i)table\"), col(\"generator_type\"))\n",
    "    )\n",
    "    # Repartitioning to 1 partition to have sequential row ids\n",
    "    df_with_table = df_with_table.repartition(1)\n",
    "\n",
    "    # Forward filling generator type and table names\n",
    "    df = df_with_table.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "    df = df.withColumn('generator_type', coalesce(col('generator_type'), last('generator_type', True).over(Window.orderBy('row_id')), lit('0')))\n",
    "    df_filled = df.withColumn('table_name', coalesce(col('table_name'), last('table_name', True).over(Window.orderBy('row_id')), lit('0')))\n",
    "\n",
    "    df_data = df_filled.filter(~col(\"generator_type\").rlike(\"(?i)table\"))\n",
    "    df_data = df_data.drop('row_id')\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_col_name(original_name, header_value):\n",
    "    \"\"\"\n",
    "    Applies all logic: header extraction, lowercase, character removal, \n",
    "    'fuel' mapping, and 'provisional' removal.\n",
    "    \"\"\"\n",
    "    name = str(header_value)\n",
    "    \n",
    "    name = (name.lower()\n",
    "            .replace(\" \", \"_\")\n",
    "            .replace(\"(\", \"\")\n",
    "            .replace(\")\", \"\")\n",
    "            .replace(\"[\", \"\")\n",
    "            .replace(\"]\", \"\")\n",
    "            .replace(\"\\n\", \"_\"))\n",
    "    \n",
    "    if \"fuel\" in name:\n",
    "        return \"fuel\"\n",
    "    \n",
    "    name = name.replace(\"_provisional\", \"\")\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_mapping(df_bronze):\n",
    "    header_row = df_bronze.filter('_c0 like \"Generator type\"').limit(1).collect()[0]\n",
    "    current_cols = df_bronze.columns\n",
    "\n",
    "    new_columns = [\n",
    "        col(old_name).alias(transform_col_name(old_name, header_row[i]))\n",
    "        for i, old_name in enumerate(current_cols)]\n",
    "    \n",
    "    df_column_mapped = df_bronze.select(*new_columns)\n",
    "    return df_column_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_float_columns(df):\n",
    "    float_cols = [f.name for f in df.schema.fields if isinstance(f.dataType, (FloatType, DoubleType))]\n",
    "    for column in float_cols:\n",
    "        df = df.withColumn(column, round(col(column), 2))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_et51_tables(bronze_path, table):\n",
    "    if table == 'main':\n",
    "        excel_data_address = \"'Main Table'!A6\"\n",
    "    elif table == 'annual':\n",
    "        excel_data_address = \"'Annual'!A5\"\n",
    "    elif table == 'quarter':\n",
    "        excel_data_address = \"'Quarter'!A5\"\n",
    "\n",
    "    df_bronze_main = (\n",
    "        spark.read\n",
    "        .format(\"com.crealytics.spark.excel\")\n",
    "        .option(\"header\", \"false\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"dataAddress\", excel_data_address)\n",
    "        .load(bronze_path)\n",
    "    )\n",
    "    df_correct_columns = column_mapping(df_bronze_main)\n",
    "    df_with_tablename = forward_fill_tablename(df_correct_columns)\n",
    "    df_cleaned = df_with_tablename.filter('generator_type not like \"Generator type\"')\n",
    "    df_final = df_cleaned.withColumn(\"fuel\", regexp_extract(col(\"fuel\"), r\"^([A-Za-z ]+)\", 1))\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_path = \"abfss://bronze@stenergyplatformadls.dfs.core.windows.net/energy_trends/prices/ET_5.1_SEP_25.xlsx\"\n",
    "\n",
    "for table in ('main', 'annual', 'quarter'):\n",
    "    silver_path = f\"abfss://silver@stenergyplatformadls.dfs.core.windows.net/energy_trends_generation/{table}/\"\n",
    "    df = clean_et51_tables(bronze_path, table)\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
