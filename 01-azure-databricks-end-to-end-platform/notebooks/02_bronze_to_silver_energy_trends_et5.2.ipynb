{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ef5c701-8827-42fe-ab29-a0fb4b51315e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Below step is only for portfolio project. In real prod, need to use service principal to link storage account to Databricks\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\n",
    "    \"fs.azure.account.key.stenergyplatformadls.dfs.core.windows.net\",\n",
    "    \"<Access key>"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cfdcec-1b8f-43f2-a5e6-a95cc66429c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f2b4db5-a668-4024-b3cd-26b78d4d3afa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, coalesce, last, monotonically_increasing_id, lit, to_date, year, month,  regexp_extract, expr, round\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import FloatType, DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10993e4a-ff22-487e-b9f6-16828f75098e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d33923ff-dd89-4ac1-96c1-28db138b4096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def cleanup_colum_names(df):\n",
    "    for c in df.columns:\n",
    "        df = df.withColumnRenamed(\n",
    "            c,\n",
    "            c.lower()\n",
    "             .replace(\" \", \"\")\n",
    "             .replace(\"(\", \"\")\n",
    "             .replace(\")\", \"\")\n",
    "             .replace(\"\\n\", \"\")\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c52a4b7-5334-4ffa-9870-fceb0608c758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_quarter_columns(df):\n",
    "    # Mapping for the messy middle part\n",
    "    mapping = {\n",
    "        \" 1st quarter\": \"_q1\",\n",
    "        \" 2nd quarter\": \"_q2\",\n",
    "        \" 3rd quarter\": \"_q3\",\n",
    "        \" 4th quarter\": \"_q4\",\n",
    "        \"\\n1st quarter\": \"_q1\",\n",
    "        \"\\n2nd quarter\": \"_q2\",\n",
    "        \"\\n3rd quarter\": \"_q3\",\n",
    "        \"\\n4th quarter\": \"_q4\",\n",
    "        \"1st\\nquarter\": \"_q1\",\n",
    "        \"2nd\\nquarter\": \"_q2\",\n",
    "        \"3rd\\nquarter\": \"_q3\",\n",
    "        \"4th\\nquarter\": \"_q4\"\n",
    "    }\n",
    "    # Generate new names by checking if the suffix exists in our mapping\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        new_name = col\n",
    "        for messy, clean in mapping.items():\n",
    "            if messy in col:\n",
    "                new_name = col.replace(messy, clean)\n",
    "        new_cols.append(new_name)\n",
    "    df = df.toDF(*new_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15fb25bf-27ae-4415-80d5-e01e0a88d742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_et52_tables(bronze_path, table):\n",
    "    if table == 'main':\n",
    "        excel_data_address = \"'Main Table'!A5\"\n",
    "    elif table == 'annual':\n",
    "        excel_data_address = \"'Annual'!A4\"\n",
    "    elif table == 'quarter':\n",
    "        excel_data_address = \"'Quarter'!A5\"\n",
    "\n",
    "    df_bronze = (\n",
    "            spark.read\n",
    "            .format(\"com.crealytics.spark.excel\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .option(\"dataAddress\", excel_data_address)  # sheet name\n",
    "            .load(bronze_path)\n",
    "            )\n",
    "    if table == 'main':\n",
    "        df_bronze = df_bronze.drop('_c14')\n",
    "        #Renaming columns\n",
    "        new_columns = ['supply_demand_components', '2023', '2024', 'annual_percent_change', 'q2_2023', 'q3_2023', 'q4_2023', 'q1_2024', 'q2_2024', 'q3_2024', 'q4_2024', 'q1_2025', 'q2_2025', 'percent_change']\n",
    "        df_bronze = df_bronze.toDF(*new_columns)\n",
    "    elif table == 'quarter':\n",
    "        df_bronze = df_bronze.withColumnRenamed(\"Components of supply and demand\", \"supply_demand_components\")\n",
    "        df_bronze = clean_quarter_columns(df_bronze)\n",
    "        for c in df_bronze.columns:\n",
    "                df_bronze = df_bronze.withColumnRenamed(\n",
    "                    c,\n",
    "                    c.lower()\n",
    "                    .replace(\"[provisional]\", \"\")\n",
    "                    .replace(\" \", \"\")\n",
    "                    .replace(\"\\n\", \"\")\n",
    "                )\n",
    "    elif table == 'annual':\n",
    "        header_row = df_bronze.first()\n",
    "        new_column_names = [str(header_row[i]) for i in range(len(header_row))]\n",
    "        df_bronze = df_bronze.toDF(*new_column_names).filter(col(new_column_names[0]) != header_row[0])\n",
    "        df_bronze = df_bronze.withColumnRenamed(\"Components of supply and demand\", \"supply_demand_components\")\n",
    "        df_bronze = cleanup_colum_names(df_bronze)\n",
    "\n",
    "    cols_to_fix = [c for c in df_bronze.columns if c != \"supply_demand_components\"]\n",
    "\n",
    "    # Apply transformations: cast to float, fill nulls with 0, and round to 2 decimals\n",
    "    df_cleaned = df_bronze.select(\n",
    "        \"supply_demand_components\",\n",
    "        *[round(coalesce(col(c).cast(\"double\"), lit(0)), 2).alias(c) for c in cols_to_fix]\n",
    "    )\n",
    "\n",
    "    #Filtering out the rows with null values\n",
    "    df_cleaned = df_bronze.filter(col('supply_demand_components').isNotNull())\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c9a410f-7bda-4491-b843-7f6d5cf756ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c7795b9-4f02-4fce-936c-bfc195dd46b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Reading ET5.1 file from bronze container\n",
    "bronze_path = \"abfss://bronze@stenergyplatformadls.dfs.core.windows.net/energy_trends/prices/ET_5.2_SEP_25.xlsx\"\n",
    "\n",
    "for table in ('main','annual', 'quarter'):\n",
    "  silver_path = f\"abfss://silver@stenergyplatformadls.dfs.core.windows.net/energy_trends_supply_demand/{table}/\"\n",
    "  df = clean_et52_tables(bronze_path, table)\n",
    "  #Write cleaned data to appropriate silver path\n",
    "  df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5be9ce7-14a4-4d99-901b-b40c36e8c4d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_bronze_to_silver_energy_trends_et5.2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}