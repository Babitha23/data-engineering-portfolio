{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below step is only for portfolio project. In real prod, need to use service principal to link storage account to Databricks\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\n",
    "    \"fs.azure.account.key.stenergyplatformadls.dfs.core.windows.net\",\n",
    "    \"ACCESS_KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, coalesce, last, monotonically_increasing_id, lit, to_date, year, month, regexp_extract, expr, round\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import FloatType, DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fill_tablename(df_bronze):\n",
    "    \"\"\"\n",
    "    Identifies table names within the generator_type column and forward-fills \n",
    "    them across subsequent rows to maintain context after filtering.\n",
    "    \n",
    "    Logic:\n",
    "    1. Extracts 'table_name' from rows where generator_type matches 'table'.\n",
    "    2. Uses a Window function over a monotonically increasing ID to forward-fill values.\n",
    "    3. Filters out the original header/metadata rows to keep only data rows.\n",
    "    \"\"\"\n",
    "    df_with_table = df_bronze.withColumn(\n",
    "        \"table_name\",\n",
    "        when(col(\"generator_type\").rlike(\"(?i)table\"), col(\"generator_type\"))\n",
    "    )\n",
    "    df_with_table = df_with_table.repartition(1)\n",
    "\n",
    "    df = df_with_table.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "    df = df.withColumn('generator_type', coalesce(col('generator_type'), last('generator_type', True).over(Window.orderBy('row_id')), lit('0')))\n",
    "    df_filled = df.withColumn('table_name', coalesce(col('table_name'), last('table_name', True).over(Window.orderBy('row_id')), lit('0')))\n",
    "\n",
    "    df_data = df_filled.filter(~col(\"generator_type\").rlike(\"(?i)table\"))\n",
    "    df_data = df_data.drop('row_id')\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_col_name(original_name, header_value):\n",
    "    \"\"\"\n",
    "    Standardizes raw Excel header strings into clean, machine-readable column names.\n",
    "    \n",
    "    Logic:\n",
    "    - Converts to lowercase and replaces spaces/newlines with underscores.\n",
    "    - Removes special characters like parentheses and brackets.\n",
    "    - Normalizes 'fuel' related columns to a single 'fuel' identifier.\n",
    "    - Strips 'provisional' suffixes for schema consistency.\n",
    "    \"\"\"\n",
    "    name = str(header_value)\n",
    "    \n",
    "    name = (name.lower()\n",
    "            .replace(\" \", \"_\")\n",
    "            .replace(\"(\", \"\")\n",
    "            .replace(\")\", \"\")\n",
    "            .replace(\"[\", \"\")\n",
    "            .replace(\"]\", \"\")\n",
    "            .replace(\"\\n\", \"_\"))\n",
    "    \n",
    "    if \"fuel\" in name:\n",
    "        return \"fuel\"\n",
    "    \n",
    "    name = name.replace(\"_provisional\", \"\")\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_mapping(df_bronze):\n",
    "    \"\"\"\n",
    "    Orchestrates the renaming of a DataFrame based on a specific header row \n",
    "    found within the data.\n",
    "    \n",
    "    Logic:\n",
    "    1. Locates the row containing 'Generator type'.\n",
    "    2. Iterates through columns and applies the transform_col_name logic.\n",
    "    3. Returns a DataFrame with the new aliased schema.\n",
    "    \"\"\"\n",
    "    header_row = df_bronze.filter('_c0 like \"Generator type\"').limit(1).collect()[0]\n",
    "    current_cols = df_bronze.columns\n",
    "\n",
    "    new_columns = [\n",
    "        col(old_name).alias(transform_col_name(old_name, header_row[i]))\n",
    "        for i, old_name in enumerate(current_cols)]\n",
    "    \n",
    "    df_column_mapped = df_bronze.select(*new_columns)\n",
    "    return df_column_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_et51_tables(bronze_path, table):\n",
    "    \"\"\"\n",
    "    Reads the excel file from bronze_path and returns a cleaned dataframe.\n",
    "    Main processing logic for ET5.1 generation data.\n",
    "    \"\"\"\n",
    "    if table == 'main':\n",
    "        excel_data_address = \"'Main Table'!A6\"\n",
    "    elif table == 'annual':\n",
    "        excel_data_address = \"'Annual'!A5\"\n",
    "    elif table == 'quarter':\n",
    "        excel_data_address = \"'Quarter'!A5\"\n",
    "\n",
    "    df_bronze_main = (\n",
    "        spark.read\n",
    "        .format(\"com.crealytics.spark.excel\")\n",
    "        .option(\"header\", \"false\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"dataAddress\", excel_data_address)\n",
    "        .load(bronze_path)\n",
    "    )\n",
    "    df_correct_columns = column_mapping(df_bronze_main)\n",
    "    df_with_tablename = forward_fill_tablename(df_correct_columns)\n",
    "    df_cleaned = df_with_tablename.filter('generator_type not like \"Generator type\"')\n",
    "    df_final = df_cleaned.withColumn(\"fuel\", regexp_extract(col(\"fuel\"), r\"^([A-Za-z ]+)\", 1))\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_path = \"abfss://bronze@stenergyplatformadls.dfs.core.windows.net/energy_trends/ET_5.1_SEP_25.xlsx\"\n",
    "\n",
    "for table in ('main', 'annual', 'quarter'):\n",
    "    silver_path = f\"abfss://silver@stenergyplatformadls.dfs.core.windows.net/energy_trends_generation/{table}/\"\n",
    "    df = clean_et51_tables(bronze_path, table)\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(silver_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
