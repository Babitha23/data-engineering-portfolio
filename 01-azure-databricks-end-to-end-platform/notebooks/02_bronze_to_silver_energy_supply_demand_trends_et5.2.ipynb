{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below step is only for portfolio project. In real prod, need to use service principal to link storage account to Databricks\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\n",
    "    \"fs.azure.account.key.stenergyplatformadls.dfs.core.windows.net\",\n",
    "    \"ACCESS_KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, coalesce, last, monotonically_increasing_id, lit, to_date, year, month, regexp_extract, expr, round\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import FloatType, DoubleType\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_colum_names(df):\n",
    "    \"\"\"\n",
    "    Performs basic string sanitization on all column names in a DataFrame.\n",
    "    \n",
    "    Used as a general utility to ensure all columns are lowercase and \n",
    "    free of spaces or special characters that can break Delta Lake schemas.\n",
    "    \"\"\"\n",
    "    for c in df.columns:\n",
    "        df = df.withColumnRenamed(\n",
    "            c,\n",
    "            c.lower()\n",
    "             .replace(\" \", \"\")\n",
    "             .replace(\"(\", \"\")\n",
    "             .replace(\")\", \"\")\n",
    "             .replace(\"\\n\", \"\")\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_quarter_columns(df):\n",
    "    \"\"\"\n",
    "    Specifically handles the irregular quarterly naming conventions found \n",
    "    in Energy Trends Excel exports.\n",
    "    \n",
    "    Maps various messy string formats (e.g., '1st\\nquarter' or ' 1st quarter') \n",
    "    to a standardized '_q1' suffix for time-series analysis.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \" 1st quarter\": \"_q1\",\n",
    "        \" 2nd quarter\": \"_q2\",\n",
    "        \" 3rd quarter\": \"_q3\",\n",
    "        \" 4th quarter\": \"_q4\",\n",
    "        \"\\n1st quarter\": \"_q1\",\n",
    "        \"\\n2nd quarter\": \"_q2\",\n",
    "        \"\\n3rd quarter\": \"_q3\",\n",
    "        \"\\n4th quarter\": \"_q4\",\n",
    "        \"1st\\nquarter\": \"_q1\",\n",
    "        \"2nd\\nquarter\": \"_q2\",\n",
    "        \"3rd\\nquarter\": \"_q3\",\n",
    "        \"4th\\nquarter\": \"_q4\"\n",
    "    }\n",
    "    new_cols = []\n",
    "    for col_name in df.columns:\n",
    "        new_name = col_name\n",
    "        for messy, clean in mapping.items():\n",
    "            if messy in col_name:\n",
    "                new_name = col_name.replace(messy, clean)\n",
    "        new_cols.append(new_name)\n",
    "    df = df.toDF(*new_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_et52_tables(bronze_path, table):\n",
    "    \"\"\"\n",
    "    Main ETL function for the ET 5.2 Supply & Demand dataset.\n",
    "    \n",
    "    Logic:\n",
    "    1. Dynamically sets Excel data addresses based on the target table.\n",
    "    2. Handles structural differences (e.g., dropping empty columns in 'Main').\n",
    "    3. Applies quarterly normalization and basic column cleanup.\n",
    "    4. Casts numeric values to DoubleType, handles nulls, and rounds to 2 decimals.\n",
    "    5. Adds new columns 'unit' and 'ingestion_date'\n",
    "    \"\"\"\n",
    "        if table == 'main':\n",
    "        excel_data_address = \"'Main Table'!A5\"\n",
    "    elif table == 'annual':\n",
    "        excel_data_address = \"'Annual'!A4\"\n",
    "    elif table == 'quarter':\n",
    "        excel_data_address = \"'Quarter'!A5\"\n",
    "\n",
    "    df_bronze = (\n",
    "            spark.read\n",
    "            .format(\"com.crealytics.spark.excel\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .option(\"dataAddress\", excel_data_address)  # sheet name\n",
    "            .load(bronze_path)\n",
    "            )\n",
    "    if table == 'main':\n",
    "        df_bronze = df_bronze.drop('_c14')\n",
    "        #Renaming columns\n",
    "        new_columns = ['supply_demand_components', '2023', '2024', 'annual_percent_change', 'q2_2023', 'q3_2023', 'q4_2023', 'q1_2024', 'q2_2024', 'q3_2024', 'q4_2024', 'q1_2025', 'q2_2025', 'percent_change']\n",
    "        df_bronze = df_bronze.toDF(*new_columns)\n",
    "    elif table == 'quarter':\n",
    "        df_bronze = df_bronze.withColumnRenamed(\"Components of supply and demand\", \"supply_demand_components\")\n",
    "        df_bronze = clean_quarter_columns(df_bronze)\n",
    "        for c in df_bronze.columns:\n",
    "                df_bronze = df_bronze.withColumnRenamed(\n",
    "                    c,\n",
    "                    c.lower()\n",
    "                    .replace(\"[provisional]\", \"\")\n",
    "                    .replace(\" \", \"\")\n",
    "                    .replace(\"\\n\", \"\")\n",
    "                )\n",
    "    elif table == 'annual':\n",
    "        header_row = df_bronze.first()\n",
    "        new_column_names = [str(header_row[i]) for i in range(len(header_row))]\n",
    "        df_bronze = df_bronze.toDF(*new_column_names).filter(col(new_column_names[0]) != header_row[0])\n",
    "        df_bronze = df_bronze.withColumnRenamed(\"Components of supply and demand\", \"supply_demand_components\")\n",
    "        df_bronze = cleanup_colum_names(df_bronze)\n",
    "\n",
    "    cols_to_fix = [c for c in df_bronze.columns if c != \"supply_demand_components\"]\n",
    "\n",
    "    # Apply transformations: cast to float, fill nulls with 0, and round to 2 decimals\n",
    "    df_cleaned = df_bronze.select(\n",
    "        \"supply_demand_components\",\n",
    "        *[round(coalesce(col(c).cast(\"double\"), lit(0)), 2).alias(c) for c in cols_to_fix]\n",
    "    )\n",
    "\n",
    "    #Filtering out the rows with null values\n",
    "    df_cleaned = df_bronze.filter(col('supply_demand_components').isNotNull())\n",
    "\n",
    "    #Add unit and ingestion date columns\n",
    "    df_final = df_cleaned.withColumn(\"unit\", lit(\"GWh\")).withColumn(\"ingestion_date\", lit(datetime.now()))\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_path = \"abfss://bronze@stenergyplatformadls.dfs.core.windows.net/energy_trends/ET_5.2_SEP_25.xlsx\"\n",
    "\n",
    "for table in ('main','annual', 'quarter'):\n",
    "    silver_path = f\"abfss://silver@stenergyplatformadls.dfs.core.windows.net/energy_trends_supply_demand/{table}/\"\n",
    "    df = clean_et52_tables(bronze_path, table)\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(silver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbsparkutils.notebook.exit(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
